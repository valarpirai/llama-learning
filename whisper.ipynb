{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5e413d-3feb-4bc1-9e0c-cac68e998df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 113MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# model = whisper.load_model(\"base\")\n",
    "model = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b9a7de-43ad-422d-a5bf-fafcebd4338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b79b71-1c10-4f5f-853c-28c4ad41d48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/admin/dev/llama/How AI Could Empower Any Business  Andrew Ng  TED.mp4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytube\n",
    "# Reading the above Taken movie Youtube link\n",
    "video = 'https://www.youtube.com/watch?v=reUZRyXxUs4&ab_channel=TED'\n",
    "data = pytube.YouTube(video)\n",
    "# Converting and downloading as 'MP4' file\n",
    "audio = data.streams.get_audio_only()\n",
    "audio.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1d61ed-2034-417c-8eba-720cf4c4a750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lama index versus Langchain. What's the difference between these two libraries? When would you want to choose one over the other? This video is for anyone like me who's just started out and was trying to figure out, like, when do I need Langchain? Or why do I need Langchain versus Lama Index? Especially because there is a big overlap. And the overlap is that you can use either of these to query your own external data using a large language model. The difference is Lama Index is more focused on giving you a set of tools to create your own kind of knowledge graph for index using these different index types. So there's a list index. You can use the vector store index, tree index. And you can arrange and assemble these indexes in a way that makes sense for your data so that you can query it. Now with Langchain, the big feature, in my opinion, at least as the agents, the agents allow you to use the language model to make decisions about what tool to use. So for example, you can use within Langchain several different indexes as a tool and then use the Langchain agent as like a router to decide, OK, when should I use this list index? Or when do I use the vector store index? So Langchain is much more robust for creating these applications. But again, there's overlap. If you're just getting started, when I was just getting started, I was all in on Lama Index until I reached what I felt like were some limitations. And then I moved over to Langchain and started getting familiar with this as well. So for anyone just getting started, start with Lama Index until you reach a roadblock where you can't get any further. And then move on over to Langchain. You'll get it a lot easier that way. At least that's how I got it. Hopefully you found this useful. Any questions, leave them in the comments.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"Langchain vs LlamaIndex.mp4\", fp16=False)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1545ca6d-c863-474f-a58e-7c56d4e15785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " When I think about the rise of AI, I'm reminded by the rise of literacy. A few hundred years ago, many people in society thought that maybe not everyone needed to be able to read and write. Back then, many people were attending fused or hurting sheep, so maybe there was less need for written communication. And all that was needed was for the high priest and priestesses and monks to be able to read the holy book, and the rest of us could just go to the temple or church or the holy building and sit and listen to the high priest and priestesses read to us. Fortunately, we're since figured out that we can build a much richer society if lots of people can read and write. Today, AI is in the hands of the high priest and priestesses. These are the highly skilled AI engineers, many of whom work on the big tech companies. And most people have access only to the AI that they build for them. I think that we can build a much richer society if we can enable everyone to help to write the future. But why is AI largely concentrated in the big tech companies? Because many of these AI projects have been expense to the bill. They may require dozens of high-disco engineers and it may cost millions or tens of millions of dollars to build an AI system. And the large tech companies, particularly the ones with hundreds of millions or even billions of users, have been better than anyone else at making these investments pay off. Because for them, one size fits all AI systems, such as one that improves web search or that recommends that the products for online shopping can be applied to this very large number of users to generate a massive amount of revenue. But this recipe for AI does not work once you go outside to tech and internet sectors to other places where, for the most part, there are hardly any projects that apply to a hundred million people or that generates comparable economics. Let me illustrate an example. Many weekends, I drive a few minutes from my house to a local pizza store to buy a slice of Hawaiian pizza from the gentleman that owns this pizza store. And his pizza is great. But he always has a lot of coat, pizza sitting around. And every weekend, some different flavor of pizza is all the style. But when I wash him off of his store, I get excited because by selling pizza, he is generating data. And this is data that he can take advantage of if he had access to AI. AI systems are good at spotting patterns when given access to the right data. And perhaps an AI system could spot if Mediterranean pizzas sell really well on a Friday night, because it suggested him to make more of it on a Friday afternoon. Now you might say to me, hey Andrew, this is a small pizza store. What's the big deal? And I say to the gentleman that owns this pizza store, something that could help him improve his revenues by a few thousand dollars a year that will be a huge deal to him. I know that there is a lot of hype about AI's need for massive data sets. And having more data does help. But contrary to the hype, AI can often work just fine, even on models and miles of data, such as the data generated by a single pizza store. So the real problem is not that there isn't enough data from the pizza store. The real problem is that the small pizza store could never serve enough customers to justify the cost of hiring an AI team. I know that in the United States, there are about half a million independent restaurants, and collectively, these restaurants do serve tens of millions of customers. But every restaurant has difference with a different menu, different customers, different ways of recording sales that no one size fits our AI will work for all of them. What would it be like if we could enable small businesses and especially local businesses to use AI? Let's take a look at what it might look like at a company that makes and sells t-shirts. I would love if in a contents working for the t-shirt company can use AI for demand forecasting, say figure out what funny means the print on t-shirts that would dry sales by looking at what's trending on social media. Or for product placement, why can't a front-to-store manager take pictures of what the store looks like and show it to an AI and have an AI recommend where to place products to improve sales? Supply chain, can an AI recommend to buyer whether or not they should pay $20 per yard for a piece of fabric now or if they should keep looking because they might be defined at cheaper elsewhere? Or quality control, a quality inspector should be able to use AI to automatically scan pictures of the fabric being used to make t-shirts to check if there are any tears or discolourations in the cloth. Today, large tech companies routinely use AI to solve problems like these and to grade effect. But a typical t-shirt company or a typical auto mechanic or retailer or school or local firm will be using AI for exactly zero of these applications today. Every t-shirt maker is sufficiently different from every other t-shirt maker that there is no one-size-bizel AI that will work for all of them. And in fact, once you go outside the internet and tech sectors in other industries, even large companies such as pharmaceutical companies, the car makers, the hospitals also struggle with this. This is the long-tailed problem of AI. If you were to take all current and potential AI projects and sort them in decreasing order of value and plot them, you'd get grounded looks like this. Maybe the single most valuable AI system is something that decides what ads to show people on the internet. Maybe the second most valuable is a web search engine, maybe the third most valuable is a online shopping product recommendation system. But when you go to the right of this curve, you then get projects like t-shirt product placements or t-shirt demand forecasting or pizzeria demand forecasting. And each of these is a unique project that needs to be custom built. Even t-shirt demand forecasting, if it depends on trending memes on on social media, is a very different project than pizzeria demand forecasting if that depends on the pizzeria sales data. So today, there are millions of projects sitting on the tail of this distribution that no one is working on, but whose aggregate value is massive. So how can we enable small businesses and individuals to build the AI systems that matter to them? For most of the last few decades, if you want to build an AI system, this is what you have to do. You have to write pages and pages of code. And while I would love for everyone to learn to code, and in fact, online education and also offline education are helping more people than ever learn to go. Unfortunately, not everyone has the time to do this. But there is an emerging new way to build AI systems that will let more people participate. Just as pen and paper, which are a vastly superior technology to stones, tablet and chisel, were instrumental to widespread literacy, there are emerging new AI development platforms that shift the focus from asking you to write lots of code, to asking you to focus on providing data, and this turns out to be much easier for a lot of people to do. Today, there are multiple companies working on platforms like these. Let me illustrate a few of the concepts using one that my team has been building. Take the example of an inspector wanting AI to help detect defects in fabric. An inspector can take pictures of the fabric and upload it to a platform like this. And they can go in to show the AI what tears in the fabric looks like by drawing rectangles. And they can also go in to show the AI what discolourations in the fabric looks like by drawing rectangles. So these pictures, together with the green and pink rectangles that the inspectors drawn, are data created by the inspector to explain to AI how to find tears and discolourations. After the AI examines this data, we may find that it has seen enough pictures of tears, but not yet enough pictures of discolourations. This is akin to if a junior inspector had learned to rely on these spot tears, but still needs to further hone the judgment about discolourations. So the inspector can go back and take more pictures of discolourations to show to the AI to help it deepen its understanding. By adjusting the data you give to the AI, you can help the AI get smarter. So an inspector using an accessible platform like this can in a few hours to a few days, and with purchasing a suitable camera setup, be able to build a custom AI system to detect defects, tears and discolourations in all the fabric being used to make t-shirts throughout the factory. And once again, you may say, hey Andrew, this is one factory, like, why is this a big deal? And I say to you, does this a big deal to that inspector whose life this makes easier? And equally, this type of technology can empower a baker to use AI to check for the quality of the cakes they're making, or a organic farmer to check the quality of the vegetables, or a furniture maker to check the quality of the wood they're using. Platforms like this will probably still need a few more years before they're easy enough to use for every Pizzeria owner, but many of these platforms are coming along, and some of them are getting to be quite usable to someone that has tech savvy today with just a bit of training. But what this means is that rather than relying on the high-prease and pieces of the right AI systems for everyone else, we can start to empower every accountant, every store manager, every buyer, and every quality inspector to build their own AI systems. I hope that the Pizzeria owner and many other small business owners like him will also take advantage of this technology, because AI is creating tremendous wealth and will continue to create tremendous wealth, and it's only by democratizing access to AI that can ensure that this wealth is spread far and wide across society. Hundreds of years ago, I think hardly anyone understood the impact that widespread literacy will have. Today, I think hardly anyone understands the impact that democratizing access to AI will have. Building AI systems has been other reach for most people, but that does not have to be the case. In the coming era of AI, we'll empower everyone to build AI systems for themselves, and I think that will be incredibly exciting future. Thank you very much.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"How AI Could Empower Any Business  Andrew Ng  TED.mp4\", fp16=False)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9875ddf-f30d-4265-8866-bbedf76bbee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
